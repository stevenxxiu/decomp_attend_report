\PassOptionsToPackage{pdfpagelabels=false}{hyperref}
\documentclass{article}
\usepackage{natbib}
\usepackage{hyperref}
\usepackage{url}
\usepackage{amssymb}
\usepackage{amsmath}
\usepackage{graphicx}
\usepackage{siunitx}
\usepackage{hhline}
\usepackage[titletoc,title]{appendix}
\usepackage[utf8]{inputenc}
\usepackage[margin=1in]{geometry}

\makeatletter
\newcommand*{\Appendixautorefname}{Appendix}
\newcommand{\specialcell}[2][c]{\begin{tabular}[#1]{@{}c@{}}#2\end{tabular}}
\newsavebox\CBox\def\textBF#1{\sbox\CBox{#1}\resizebox{\wd\CBox}{\ht\CBox}{\textbf{#1}}}\parindent=0pt
\sisetup{exponent-product = \cdot}
\setlength{\parskip}{0.8em}
\renewcommand\hyper@natlinkbreak[2]{#1}
\makeatother

\begin{document}

\title{Reproduction of A Decomposable Attention Model for Natural Language Inference}

\author{
  \textbf{Xingyi Xu} \\ University of Melbourne \\ \texttt{stevenxxiu@gmail.com} \and
  \textbf{Jey Han Lau} \\ IBM Research \\ \texttt{depthchargex@gmail.com} \and
  \textbf{Timothy Baldwin} \\ University of Melbourne \\ \texttt{tb@ldwin.net}
}
\maketitle

\begin{abstract}
Neural network models can be difficult to reproduce due to its many hyperparameters, initialization and training details. We attempted to reproduce the results of a paper ``A Decomposable Attention Model for Natural Language Inference'' for the stanford natural language inference dataset, using \texttt{tensorflow}. For the vanilla approach, we obtained an accuracy of 85.9\%, comparable to the paper's 86.3\%. However for the intra-sentence approach, we did not find an improvement, and instead found significant overfitting and obtained a lower accuracy of 85.7\%, in comparison to the paper's 86.8\%.
\end{abstract}

\section{Introduction}
The recent resurgence in AI is in large part due to the many successful neural network models. These models often have many hyperparameters, and can be initialized and trained in multiple ways. However, the focus on many papers has been just the model itself, with a minimal or neglected description of the details, possibly due to the fact that different initilization and training schemes can still achieve similar results. Hence it is useful to investigate whether we can reproduce neural network papers using its description alone, and if not, what can be done to improve reproducibility.

We investigate a paper in the space of natural language inference. This is the problem of given two sentences, determining whether sentence 2 entails (E), contradicts (C), or is neutral (N) to sentence 1. Examples are given in \autoref{table:examples}.

\begin{table}[htbp]\centering
\setlength\tabcolsep{2pt}
\begin{tabular}{|p{7.5cm}|p{7.5cm}|r|}
    \hline
    Sentence 1 & Sentence 2 & Label \\ \hhline{|===|}
    A man inspects the uniform of a figure in some East Asian country. & The man is sleeping & C \\ \hline
    An older and younger man smiling. & Two men are smiling and laughing at the cats playing on the floor. & N \\ \hline
    A black race car starts up in front of a crowd of people. & A man is driving down a lonely road. & C \\ \hline
    A soccer game with multiple males playing. & Some men are playing a sport. & E \\ \hline
    A smiling costumed woman is holding an umbrella. & A happy woman in a fairy costume holds an umbrella. & E \\ \hline
\end{tabular}
\caption{Examples from the Stanford Natural Langauge Inference (SNLI) dataset.}
\label{table:examples}
\end{table}

The paper ``A Decomposable Attention Model for Natural Language Inference'' \citep{parikh_decomposable_2016} is interesting in that despite being a model with a relatively low 580k parameters, it achieves a good claimed accuracy of 86.8\% on the SNLI dataset \citep{snli:emnlp2015}, which is not too far behind the current best model of 88.8\% accuracy, with 6.4m parameters. Another aspect is that the vanilla part of the model does not take any word ordering into account, however still manages to achieve a claimed accuracy of 86.3\%. For these reasons we decided to investigate this particular paper.

In the following sections, we give a description the vanilla and intra-sentence models, any ambiguities in the paper which slowed down our implementation, and a report of how we managed to implement the model.

\section{Models}
We found the model to be very well described, and there were few ambiguities which slowed down our implementation. The only part that may be unclear is the training objective's dropout being stated in the experimental section. We now describe the model using the paper's notation for the purpose of being self-contained.

\section{Ambiguities in experimental results}

XXX mention the thing about fixed word embeddings in test set possibly causing an implementation issue

\subsection{Results}

\begin{table}[htbp]\centering
\begin{tabular}{|l|r|}
    \hline
    Method     & Accuracy \\ \hline
    \hline
\end{tabular}
\caption{Classification results for the SNLI dataset. XXX.}
\label{table:results}
\end{table}

\section{Conclusion}
We have described the process in which we attempted to reproduce the paper ``Reproduction of A Decomposable Attention Model for Natural Language Inference''. XXX. We hope that our findings can guide future paper authors in the area of deep learning to describe their models in a clearer fashion so that they are more easily reproducible.

\bibliography{main}{}
\bibliographystyle{apalike}

\end{document}
